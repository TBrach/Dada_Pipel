LevelsWant <- as.character(ReadSummary$Sample)
for (i in seq_along(LevelsWant)) {
ReadSummary$Sample <- relevel(ReadSummary$Sample, ref = LevelsWant[i])
}
}
## Construct the plotting data frame
#ReadSummary <- subset(ReadSummary, select = c("Sample", "UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera"))
ReadSummary <- subset(ReadSummary, select = c("Sample", "FilteredReads", "UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera"))
# colnames(ReadSummary)[2:5] <- c("all", "filtered", "denoised_FW", "denoised_RV", "merged", "nochim")
# colnames(ReadSummary)[2:5] <- c("all", "filtered", "merged", "nochim")
ReadSummary <- tidyr::gather(ReadSummary, key = Type, value = NoReads, -Sample)
#color_levels <- cbPalette[2:7]
#names(color_levels) <- c("UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera")
#ReadSummary$Type <- factor(ReadSummary$Type, levels = c("UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera"), ordered = T)
color_levels <- cbPalette
names(color_levels) <- c("FilteredReads", "UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera")
ReadSummary$Type <- factor(ReadSummary$Type, levels = c("FilteredReads", "UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera"), ordered = T)
Tr <- ggplot(data = ReadSummary, aes(x = Sample, y = NoReads, color = Type))
Tr <- Tr +
# geom_hline(yintercept = 10000, color = 'darkred', linetype = "dashed", size = .35) +
geom_point(size = 2) +
scale_color_manual(values = color_levels) +
ylab("No Unique Sequences") +
xlab("") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.major.x = element_line(color = "#999999", size = .15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 6),
legend.title = element_blank()) +
scale_y_log10()
Tr
}
NoUniques_StepsSimple2(ReadSummary = ReadSummary, SampleNames = SampleNames, sort = TRUE)
colnames(ReadSummary)
# - print the percentage of unique filtered reads that are not singletons -
ReadSummary2 <- mutate(ReadSummary, PC_NonSingletonUniqueFilteredReads_F = 1-UniqueFilteredReadSingletons_F/UniqueSequences_F,
PC_NonSingletonUniqueFilteredReads_R = 1-UniqueFilteredReadSingletons_R/UniqueSequences_R)
ReadSummary2 <- select(ReadSummary2, Sample, PC_NonSingletonUniqueFilteredReads_F, PC_NonSingletonUniqueFilteredReads_R)
View(ReadSummary2)
# - print the percentage of unique filtered reads that are not singletons -
ReadSummary2 <- mutate(ReadSummary, PC_NonSingletonUniqueFilteredReads_F = 100*(1-UniqueFilteredReadSingletons_F/UniqueSequences_F),
PC_NonSingletonUniqueFilteredReads_R = 100*(1-UniqueFilteredReadSingletons_R/UniqueSequences_R))
ReadSummary2 <- select(ReadSummary2, Sample, PC_NonSingletonUniqueFilteredReads_F, PC_NonSingletonUniqueFilteredReads_R)
ReadSummary2 <- gather(ReadSummary2, key = Type, value = PC, -Sample)
ReadSummary2
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
Tr <- ggplot(ReadSummary2, aes(x = Sample, y = PC, col = Type))
Tr <- ggplot(ReadSummary2, aes(x = Sample, y = PC, col = Type))
Tr +
geom_point(size = 2) +
scale_color_manual(values = c(cbPalette[2], cbPalette[4])) +
ylab("PC of unique filtered reads that are not singletons") +
xlab("") +
theme_bw()
Tr <- ggplot(ReadSummary2, aes(x = Sample, y = PC, col = Type))
Tr <- Tr +
geom_point(size = 2) +
scale_color_manual("", values = c(cbPalette[2], cbPalette[4])) +
ylab("PC of unique filtered reads that are not singletons") +
xlab("") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.major.x = element_line(color = "#999999", size = .15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 6),
legend.title = element_blank())
Tr
Percentage_NonSingletonUniqueFilteredReads <- function(ReadSummary, SampleNames, sort = FALSE) {
if (!all(SampleNames %in% ReadSummary$Sample)) {
stop("not all SampleNames were found in the given ReadSummary")
}
ReadSummary <- ReadSummary[ReadSummary$Sample %in% SampleNames,]
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
if (sort) {
ReadSummary <- dplyr::arrange(ReadSummary, desc(NoReads))
LevelsWant <- as.character(ReadSummary$Sample)
for (i in seq_along(LevelsWant)) {
ReadSummary$Sample <- relevel(ReadSummary$Sample, ref = LevelsWant[i])
}
}
ReadSummary2 <- mutate(ReadSummary, PC_NonSingletonUniqueFilteredReads_F = 100*(1-UniqueFilteredReadSingletons_F/UniqueSequences_F),
PC_NonSingletonUniqueFilteredReads_R = 100*(1-UniqueFilteredReadSingletons_R/UniqueSequences_R))
ReadSummary2 <- select(ReadSummary2, Sample, PC_NonSingletonUniqueFilteredReads_F, PC_NonSingletonUniqueFilteredReads_R)
ReadSummary2 <- gather(ReadSummary2, key = Type, value = PC, -Sample)
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
Tr <- ggplot(ReadSummary2, aes(x = Sample, y = PC, col = Type))
Tr <- Tr +
geom_point(size = 2) +
scale_color_manual("", values = c(cbPalette[2], cbPalette[4])) +
ylab("PC of unique filtered reads that are not singletons") +
xlab("") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.major.x = element_line(color = "#999999", size = .15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 6),
legend.title = element_blank())
Tr
}
Percentage_NonSingletonUniqueFilteredReads(ReadSummary = ReadSummary, SampleNames = SampleNames)
seqtab
apply(seqtab, 1, function(x){sum(x > 0)})
seqtab.nochim.Pooled <- removeBimeraDenovo(seqtab, method="pooled", verbose = T)
seqtab.nochim.PerSample <- removeBimeraDenovo(seqtab, method="per-sample", verbose = T)
apply(seqtab.nochim.PerSample, 1, function(x){sum(x > 0)})
?removeBimeraDenovo
NoBimerasPooled <- ncol(seqtab) - ncol(seqtab.nochim.Pooled)
NoBimerasPerSample <- ncol(seqtab) - ncol(seqtab.nochim.PerSample)
NoBimerasConsensus <- ncol(seqtab) - ncol(seqtab.nochim.Consensus)
seqtab.nochim.Consensus <- removeBimeraDenovo(seqtab, method="consensus", verbose = T)
NoBimerasPooled <- ncol(seqtab) - ncol(seqtab.nochim.Pooled)
NoBimerasPerSample <- ncol(seqtab) - ncol(seqtab.nochim.PerSample)
NoBimerasConsensus <- ncol(seqtab) - ncol(seqtab.nochim.Consensus)
NoBimerasPooled
NoBimerasPerSample
NoBimerasConsensus
?isBimeraDenovo
colSums(seqtab)
pooledSeqtab <- matrix(colSums(seqtab), ncol = ncol(seqtab), dimnames = list("", colnames(seqtab)))
class(pooledSeqtab)
dim(pooledSeqtab)
dim(seqtab)
identical(sum(isBimeraDenovo(pooledSeqtab)), NoBimerasPooled)
apply(seqtab, 1, function(x){sum(x > 0)})
Seqtab2 <- seqtab > 0
View(Seqtab2)
colnames(Seqtab2) <- paste0("T", 1:807)
View(Seqtab2)
seqtabS1 <- seqtab[c(1,3,4),]
colSums(seqtabS1)
seqtabS1 <- seqtabS1[, colSums(seqtabS1) > 0]
dim(seqtabS1)
apply(seqtabS1, 1, function(x){x > 0})
apply(seqtabS1, 1, function(x){sum(x > 0)})
apply(seqtab, 1, function(x){sum(x > 0)})
seqtab.nochim.PooledS1 <- removeBimeraDenovo(seqtabS1, method="pooled", verbose = T)
apply(seqtab.nochim.PooledS1, 1, function(x){sum(x > 0)})
seqtab.nochim.PerSampleS1 <- removeBimeraDenovo(seqtabS1, method="per-sample", verbose = T)
apply(seqtab.nochim.PerSampleS1, 1, function(x){sum(x > 0)})
View(seqtabS1)
seqtabS1_3 <- seqtabS1[2,]
class(seqtabS1_3)
length(seqtabS1_3)
seqtabS1_30 <- seqtabS1_3[seqtabS1_3 > 0]
length(seqtabS1_30)
isBimeraDenovo(seqtabS1_30)
sum(isBimeraDenovo(seqtabS1_30))
297-166
444-297
147+166
147+131
dim(seqtab)
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500_Pooled/"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
rm(list = ls())
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/"
dir(datapath)
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/"
load(file.path(datapath, "Dada_Data/Dada_Data.RData"))
load(file.path(datapath, "Dada_Data.RData"))
rm(list = ls())
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/"
dir(datapath)
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/Dada_Data"
dir(datapath)
load(file.path(datapath, "DenoisedData.RData"))
# --
dim(seqtab)
apply(seqtab, 1, function(row){sum(row > 0)})
807/3
min(seqtab)
min(seqtab[seqtab > 0])
sum(seqtab == 1)
sum(seqtab == 1)
# remove bimeras with the three different methods
seqtab.nochim.Pooled <- removeBimeraDenovo(seqtab, method="pooled", verbose = T)
seqtab.nochim.PerSample <- removeBimeraDenovo(seqtab, method="per-sample", verbose = T)
seqtab.nochim.Consensus <- removeBimeraDenovo(seqtab, method="consensus", verbose = T)
NoBimerasPooled <- ncol(seqtab) - ncol(seqtab.nochim.Pooled)
NoBimerasPerSample <- ncol(seqtab) - ncol(seqtab.nochim.PerSample)
NoBimerasConsensus <- ncol(seqtab) - ncol(seqtab.nochim.Consensus)
OverviewDF <- data.frame(Method = c("pooled", "per-sample", "consensus"), c(NoBimerasPooled, NoBimerasPerSample, NoBimerasConsensus))
OverviewDF
isBimeraDenovo(colSums(seqtab))
pooledSeqtab <- matrix(colSums(seqtab), ncol = ncol(seqtab), dimnames = list("", colnames(seqtab)))
identical(sum(isBimeraDenovo(pooledSeqtab)), NoBimerasPooled)
dim(seqtab.nochim.Pooled)
# So here you sum up the abundances of the ASV in all Samples. Then you run isBemeraDenovo. There is the option that a low abundant ASV from a sample
# is considered bimera based on parents that were only found in another sample. This could be considered weird.
# on the other hand there is the option that an ASV is low abundant in one sample but more abundant in another and does not become bimera.
# let's compare, i.e. for each sample find overlap, ASV that did become Bimera only in pooled and only in per Sample
NoASVs <- apply(seqtab, 1, function(row){sum(row > 0)})
NoASVs
isBimeraDenovo(pooledSeqtab)
BimeraPooled <- isBimeraDenovo(pooledSeqtab)
class(BimeraPooled)
length(BimeraPooled)
head(BimeraPooled)
?intersect
Test <- seqtab[1,] > 0
Test
sum(Test & BimeraPooled)
NoBimeraPooled <- apply(seqtab, 1, function(row){
Test <- row > 0
sum(Test & BimeraPooled)
})
NoBimeraPooled
NoASVs
NoASVs - NoBimeraPooled
apply(seqtab.nochim.Pooled, 1, function(row){sum(row > 0)})
NoASVs - apply(seqtab.nochim.Pooled, 1, function(row){sum(row > 0)})
BimeraPerSample <- NoASVs - apply(seqtab.nochim.PerSample, 1, function(row){sum(row > 0)})
BimeraPerSample
NoBimeraPerSample <- NoASVs - apply(seqtab.nochim.PerSample, 1, function(row){sum(row > 0)})
NoBimeraPooled
NoBimeraPerSample
mat <- t(apply(seqtab, 1, isBimeraDenovo))
View(mat)
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
rowSums(BimerPerSample > 0)
rowSums(BimeraPerSample > 0)
seqtabLogical <- seqtab > 0
seqtabLogical[1:5, 1:5]
Overalp <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & BimeraPooled)})
Overalp
Overlap <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & BimeraPooled)})
Overlap
NoBimeraPerSample
OnlyPooled <- sapply(1:6, function(i){sum(seqtabLogical[i,] & !BimeraPerSample[i,] & BimeraPooled)})
OnlyPooled
OnlyPerSample <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & !BimeraPooled)})
OnlyPerSample
SumDF <- data.frame(Sample = rownames(seqtab), NoASV = NoASVs)
SumDF
SumDF <- data.frame(Sample = rownames(seqtab), NoASV = NoASVs, NoBimeraPooled = NoBimeraPooled, NoBimeraPerSample = NoBimeraPerSample,
Overlap = Overlap, OnlyPooled = OnlyPooled, OnlyPerSample = OnlyPerSample)
SumDF
rm(list = ls())
# - load the seqtab (NB: if this path does not exist find whatever seqtab) -
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/Dada_Data"
load(file.path(datapath, "DenoisedData.RData"))
# --
dim(seqtab) # six samples rows, and 807 ASV
# the interesting thing about this seqtab is that Samples 1 3 4 and 2 5 6 are from the same Person (even stool sample)
apply(seqtab, 1, function(row){sum(row > 0)}) # not a single sample has more than 300 of these 807 ASV that are found in all smaples
min(seqtab[seqtab > 0]) # yes there are in fact two singletons in this dataset to my surprise
sum(seqtab == 1)
# remove bimeras with the three different methods
seqtab.nochim.Pooled <- removeBimeraDenovo(seqtab, method="pooled", verbose = T)
seqtab.nochim.PerSample <- removeBimeraDenovo(seqtab, method="per-sample", verbose = T)
seqtab.nochim.Consensus <- removeBimeraDenovo(seqtab, method="consensus", verbose = T)
NoBimerasPooled <- ncol(seqtab) - ncol(seqtab.nochim.Pooled)
NoBimerasPerSample <- ncol(seqtab) - ncol(seqtab.nochim.PerSample)
NoBimerasConsensus <- ncol(seqtab) - ncol(seqtab.nochim.Consensus)
OverviewDF <- data.frame(Method = c("pooled", "per-sample", "consensus"), c(NoBimerasPooled, NoBimerasPerSample, NoBimerasConsensus))
OverviewDF
OverviewDF <- data.frame(Method = c("pooled", "per-sample", "consensus"), NoBimeras =  c(NoBimerasPooled, NoBimerasPerSample, NoBimerasConsensus))
OverviewDF
# -- "per-sample": run isBimeraDenovo on each sample, i.e. row in seqtab --
mat <- t(apply(seqtab, 1, isBimeraDenovo))
# -- "per-sample": run isBimeraDenovo on each sample, i.e. row in seqtab --
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
BimeraPerSample[1:5, 1:5]
rowSums(BimeraPerSample)
# it also checks for sequences with abundance = 0 and puts them all to Bimera
rowSums(BimeraPerSample)
seqtab.PS <- seqtab
seqtab.PS[BimeraPerSample] <- 0
NoBimerasPerSample
identical(NoBimerasPerSample, sum(colSums(seqtab.PS) == 0)) # TRUE
# so to get the actual bimeras found in each sample you have to count only those that were not zero abundant
seqtabLogical <- seqtab > 0
NoBimeraPerSample <- sapply(1:6, function(i){sum(BimeraPerSample[i,] & seqtabLogical[i,])})
NoBimeraPerSample
# quickly prove that the isBimeraDenovo result is the same for a sample if you ignored the zeros from the beginning
isBimeraDenovo(seqtab[1, seqtab[1,] > 0])
# quickly prove that the isBimeraDenovo result is the same for a sample if you ignored the zeros from the beginning
sum(isBimeraDenovo(seqtab[1, seqtab[1,] > 0]))
NoBimeraPerSample
# quickly prove that the isBimeraDenovo result is the same for a sample if you ignored the zeros from the beginning
NoBimeraPerSample2 <- sapply(1:6, function(i){sum(isBimeraDenovo(seqtab[i, seqtab[i,] > 0])})
# quickly prove that the isBimeraDenovo result is the same for a sample if you ignored the zeros from the beginning
NoBimeraPerSample2 <- sapply(1:6, function(i) {sum(isBimeraDenovo(seqtab[i, seqtab[i,] > 0]))})
identical(NoBimeraPerSample, NoBimeraPerSample2)
# -- compare Pooled directly to PerSample to understand the situaiton a bit better --
# In Pooled you sum up the abundances of the ASV in all Samples and then you run isBemeraDenovo. There is the option that a low abundant ASV from a sample
# is considered bimera based on parents that were only found in another sample. This could be considered weird.
# on the other hand, there is also the option that an ASV is low abundant in one sample but more abundant in another and does not become bimera.
# let's compare, i.e. for each sample find overlap, ASV that did become Bimera only in pooled and only in per Sample
NoASVs <- apply(seqtab, 1, function(row){sum(row > 0)})
BimeraPooled <- isBimeraDenovo(pooledSeqtab)
NoBimeraPooled <- apply(seqtab, 1, function(row){
Test <- row > 0
sum(Test & BimeraPooled)
})
NoBimeraPerSample <- NoASVs - apply(seqtab.nochim.PerSample, 1, function(row){sum(row > 0)})
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
seqtabLogical <- seqtab > 0
Overlap <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & BimeraPooled)})
OnlyPooled <- sapply(1:6, function(i){sum(seqtabLogical[i,] & !BimeraPerSample[i,] & BimeraPooled)})
OnlyPerSample <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & !BimeraPooled)})
SumDF <- data.frame(Sample = rownames(seqtab), NoASV = NoASVs, NoBimeraPooled = NoBimeraPooled, NoBimeraPerSample = NoBimeraPerSample,
Overlap = Overlap, OnlyPooled = OnlyPooled, OnlyPerSample = OnlyPerSample)
# -- compare Pooled directly to PerSample to understand the situaiton a bit better --
# In Pooled you sum up the abundances of the ASV in all Samples and then you run isBemeraDenovo. There is the option that a low abundant ASV from a sample
# is considered bimera based on parents that were only found in another sample. This could be considered weird.
# on the other hand, there is also the option that an ASV is low abundant in one sample but more abundant in another and does not become bimera.
# let's compare, i.e. for each sample find overlap, ASV that did become Bimera only in pooled and only in per Sample
NoASVs <- apply(seqtab, 1, function(row){sum(row > 0)})
BimeraPooled <- isBimeraDenovo(pooledSeqtab)
pooledSeqtab <- matrix(colSums(seqtab), ncol = ncol(seqtab), dimnames = list("", colnames(seqtab)))
identical(sum(isBimeraDenovo(pooledSeqtab)), NoBimerasPooled)
# -- compare Pooled directly to PerSample to understand the situation a bit better --
# In Pooled you sum up the abundances of the ASV in all Samples and then you run isBemeraDenovo. There is the option that a low abundant ASV from a sample
# is considered bimera based on parents that were only found in another sample. This could be considered weird.
# on the other hand, there is also the option that an ASV is low abundant in one sample but more abundant in another and does not become bimera.
# let's compare, i.e. for each sample find overlap, ASV that did become Bimera only in pooled and only in per Sample
NoASVs <- apply(seqtab, 1, function(row){sum(row > 0)})
BimeraPooled <- isBimeraDenovo(pooledSeqtab)
NoBimeraPooled <- apply(seqtab, 1, function(row){
Test <- row > 0
sum(Test & BimeraPooled)
})
NoBimeraPerSample <- NoASVs - apply(seqtab.nochim.PerSample, 1, function(row){sum(row > 0)})
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
seqtabLogical <- seqtab > 0
Overlap <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & BimeraPooled)})
OnlyPooled <- sapply(1:6, function(i){sum(seqtabLogical[i,] & !BimeraPerSample[i,] & BimeraPooled)})
OnlyPerSample <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & !BimeraPooled)})
SumDF <- data.frame(Sample = rownames(seqtab), NoASV = NoASVs, NoBimeraPooled = NoBimeraPooled, NoBimeraPerSample = NoBimeraPerSample,
Overlap = Overlap, OnlyPooled = OnlyPooled, OnlyPerSample = OnlyPerSample)
SumDF
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis/"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
filtFs <- list.files("/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis/Dada_FilteredFastqs/", full.names = T)
filtRs <- filtFs[seq(2, 12, by = 2)]
filtFs <- filtFs[seq(1, 11, by = 2)]
names(filtFs) <- names(F_QualityStats)
names(filtRs) <- names(F_QualityStats)
filtFs
rm(list = ls())
# - load the seqtab (NB: if this path does not exist find whatever seqtab) -
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/Dada_Data"
load(file.path(datapath, "DenoisedData.RData"))
# --
dim(seqtab) # six samples rows, and 807 ASV
# the interesting thing about this seqtab is that Samples 1 3 4 and 2 5 6 are from the same Person (even stool sample)
apply(seqtab, 1, function(row){sum(row > 0)}) # not a single sample has more than 300 of these 807 ASV that are found in all smaples
min(seqtab[seqtab > 0]) # yes there are in fact two singletons in this dataset to my surprise
sum(seqtab == 1)
# remove bimeras with the three different methods
seqtab.nochim.Pooled <- removeBimeraDenovo(seqtab, method="pooled", verbose = T)
seqtab.nochim.PerSample <- removeBimeraDenovo(seqtab, method="per-sample", verbose = T)
seqtab.nochim.Consensus <- removeBimeraDenovo(seqtab, method="consensus", verbose = T)
NoBimerasPooled <- ncol(seqtab) - ncol(seqtab.nochim.Pooled)
NoBimerasPerSample <- ncol(seqtab) - ncol(seqtab.nochim.PerSample)
NoBimerasConsensus <- ncol(seqtab) - ncol(seqtab.nochim.Consensus)
?isBimeraDenovoTable
bim <- isBimeraDenovoTable(seqtab)
identical(seqtab.nochim.Consensus, bim)
class(bim)
bim
length(bim)
# exclude
mat[seqtab == 0] <- NA
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
seqtab.nochim.Consensus[1:5, 1:5]
BimeraPerSample[1:5, 1:5]
mat <- seqtab
mat[seqtab == 0] <- NA
NumberOfTrues <- colSums(mat, na.rm = T)
NumberOfTrues
NumberOfFalses <- colSums(!mat, na.rm = T)
NumberOfFalses
NoBimerasConsensus
bimeraConsensus <- isBimeraDenovoTable(seqtab)
length(bimeraConsensus)
BimeraPerSample[seqtab == 0] <- NA
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
NumberOfTrues
NumberOfFalses
# see ignoreNNegatives in isBimeraDenovo is by default 1, so reduce Number of FALSES by 1
NumberOfFalses[NumberOfFalses > 0] <- NumberOfFalses[NumberOfFalses > 0] - 1
Total <- NumberOfTrues + NumberOfFalses
Total
Fraction <- NumberOfTrues/Total
Fraction
NoBimerasConsensus
sum(Fraction >= 0.9, na.rm = T)
SumDF
rm(list = ls())
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_filteredReads42500/Dada_Data"
load(file.path(datapath, "DenoisedData.RData"))
# --
dim(seqtab) # six samples rows, and 807 ASV
# the interesting thing about this seqtab is that Samples 1 3 4 and 2 5 6 are from the same Person (even stool sample)
apply(seqtab, 1, function(row){sum(row > 0)}) # not a single sample has more than 300 of these 807 ASV that are found in all smaples
min(seqtab[seqtab > 0]) # yes there are in fact two singletons in this dataset to my surprise
sum(seqtab == 1)
# remove bimeras with the three different methods
seqtab.nochim.Pooled <- removeBimeraDenovo(seqtab, method="pooled", verbose = T)
seqtab.nochim.PerSample <- removeBimeraDenovo(seqtab, method="per-sample", verbose = T)
seqtab.nochim.Consensus <- removeBimeraDenovo(seqtab, method="consensus", verbose = T)
NoBimerasPooled <- ncol(seqtab) - ncol(seqtab.nochim.Pooled)
NoBimerasPerSample <- ncol(seqtab) - ncol(seqtab.nochim.PerSample)
NoBimerasConsensus <- ncol(seqtab) - ncol(seqtab.nochim.Consensus)
OverviewDF <- data.frame(Method = c("pooled", "per-sample", "consensus"), NoBimeras =  c(NoBimerasPooled, NoBimerasPerSample, NoBimerasConsensus))
# so you see that pooled removes most ASV, per-sample the least and consensus is in between
# let's try to understand the methods one by one and go a bit more into detail with what is removed
# -- "pooled": just run isBimeraDenovo on colSums(seqtab) --
pooledSeqtab <- matrix(colSums(seqtab), ncol = ncol(seqtab), dimnames = list("", colnames(seqtab)))
identical(sum(isBimeraDenovo(pooledSeqtab)), NoBimerasPooled)
# TRUE
# ----
# -- "per-sample": run isBimeraDenovo on each sample, i.e. row in seqtab --
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
# it also checks for sequences with abundance = 0 and puts them all to Bimera
rowSums(BimeraPerSample)
# so to get the actual bimeras found in each sample you have to count only those that were not zero abundant
seqtabLogical <- seqtab > 0
NoBimeraPerSample <- sapply(1:6, function(i){sum(BimeraPerSample[i,] & seqtabLogical[i,])})
# quickly prove that the isBimeraDenovo result is the same for a sample if you ignored the zeros from the beginning
NoBimeraPerSample2 <- sapply(1:6, function(i) {sum(isBimeraDenovo(seqtab[i, seqtab[i,] > 0]))})
identical(NoBimeraPerSample, NoBimeraPerSample2)
# ----
# -- compare Pooled directly to PerSample to understand the situation a bit better --
# In Pooled you sum up the abundances of the ASV in all Samples and then you run isBemeraDenovo. There is the option that a low abundant ASV from a sample
# is considered bimera based on parents that were only found in another sample. This could be considered weird.
# on the other hand, there is also the option that an ASV is low abundant in one sample but more abundant in another and does not become bimera.
# let's compare, i.e. for each sample find overlap, ASV that did become Bimera only in pooled and only in per Sample
NoASVs <- apply(seqtab, 1, function(row){sum(row > 0)})
BimeraPooled <- isBimeraDenovo(pooledSeqtab)
NoBimeraPooled <- apply(seqtab, 1, function(row){
Test <- row > 0
sum(Test & BimeraPooled)
})
NoBimeraPerSample <- NoASVs - apply(seqtab.nochim.PerSample, 1, function(row){sum(row > 0)})
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
seqtabLogical <- seqtab > 0
Overlap <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & BimeraPooled)})
OnlyPooled <- sapply(1:6, function(i){sum(seqtabLogical[i,] & !BimeraPerSample[i,] & BimeraPooled)})
OnlyPerSample <- sapply(1:6, function(i){sum(seqtabLogical[i,] & BimeraPerSample[i,] & !BimeraPooled)})
SumDF <- data.frame(Sample = rownames(seqtab), NoASV = NoASVs, NoBimeraPooled = NoBimeraPooled, NoBimeraPerSample = NoBimeraPerSample,
Overlap = Overlap, OnlyPooled = OnlyPooled, OnlyPerSample = OnlyPerSample)
SumDF
BimeraPerSample <- t(apply(seqtab, 1, isBimeraDenovo))
BimeraPerSample[seqtab == 0] <- NA
rowSums(BimeraPerSample, na.rm = T)
NoBimerasConsensus
bimeraConsensus <- isBimeraDenovoTable(seqtab)
sum(bimeraConsensus)
identical(sum(bimeraConsensus), NoBimerasConsensus)
rowSums(BimeraPerSample, na.rm = T)
# NB: rowSums(BimeraPerSample, na.rm = T) is again NoBimeraPerSample as in SumDF
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
range(NumberOfTrues)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
range(NumberOfFalses)
# see ignoreNNegatives in isBimeraDenovo is by default 1, so reduce Number of FALSES by 1
NumberOfFalses[NumberOfFalses > 0] <- NumberOfFalses[NumberOfFalses > 0] - 1
range(NumberOfFalses)
Total <- NumberOfTrues + NumberOfFalses
range(Total)
# NB: rowSums(BimeraPerSample, na.rm = T) is again NoBimeraPerSample as in SumDF
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
# NB: rowSums(BimeraPerSample, na.rm = T) is again NoBimeraPerSample as in SumDF
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
# see ignoreNNegatives in isBimeraDenovo is by default 1, so reduce Number of FALSES by 1
NumberOfFalses[NumberOfFalses > 0] <- NumberOfFalses[NumberOfFalses > 0] - 1
Total <- NumberOfTrues + NumberOfFalses
Fraction <- NumberOfTrues/Total
Fraction
sum(Fraction > 0.9)
sum(Fraction > 0.9, na.rm = T)
NoBimerasPerSample
Fraction
sum(is.na(Fraction))
1/0
# NB: rowSums(BimeraPerSample, na.rm = T) is again NoBimeraPerSample as in SumDF
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
sum(is.na(NumberOfTrues))
sum(is.na(NumberOfFalses))
# NB: rowSums(BimeraPerSample, na.rm = T) is again NoBimeraPerSample as in SumDF
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
# see ignoreNNegatives in isBimeraDenovo is by default 1, so reduce Number of FALSES by 1
NumberOfFalses[NumberOfFalses > 0] <- NumberOfFalses[NumberOfFalses > 0] - 1
Total <- NumberOfTrues + NumberOfFalses
sum(is.na(Total))
range(Total)
0/0
# NB: rowSums(BimeraPerSample, na.rm = T) is again NoBimeraPerSample as in SumDF
NumberOfTrues <- colSums(BimeraPerSample, na.rm = T)
NumberOfFalses <- colSums(!BimeraPerSample, na.rm = T)
# see ignoreNNegatives in isBimeraDenovo is by default 1, so reduce Number of FALSES by 1
NumberOfFalses[NumberOfFalses > 0] <- NumberOfFalses[NumberOfFalses > 0] - 1
Total <- NumberOfTrues + NumberOfFalses
Fraction <- NumberOfTrues/Total
sum(is.na(Fraction))
Fraction
rm(list = ls())
