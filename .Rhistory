if (is.null(rare_max_total)){
rare_max_total <- quantile(sample_sums(ps), probs = .25)
}
Inputs_phyloseqAnalysis <- list(extra_level = extra_level,
prevalence = prevalence,
min_obs = min_obs,
taxa_sums_quantile = taxa_sums_quantile,
seed = seed,
step_size = step_size,
rare_level = rare_level,
rare_type = rare_type,
rare_max_total = rare_max_total,
taxa_are_rows = taxa_are_rows,
group_var = group_var,
group_var_levels = group_var_levels,
second_ccp_variable = second_ccp_variable,
shape = shape,
alpha_div_measures = alpha_div_measures,
alpha_at_genus = alpha_at_genus,
dist_methods = dist_methods,
datapath = datapath,
taxonomy.path = taxonomy.path,
tree.path = tree.path,
sample.path = sample.path,
functionpath = functionpath)
Inputs_phyloseqAnalysis <- data.frame(Argument = names(Inputs_phyloseqAnalysis),
Value = sapply(Inputs_phyloseqAnalysis, function(x){
if (is.null(x)){
"NULL"
} else if (length(x) > 7) {
"long entry"
} else if (length(x) > 1 && length(x) < 8){
paste(x, collapse = "; ")
} else {
as.character(x)
}}))
rownames(Inputs_phyloseqAnalysis) <- NULL
# ----
knitr::kable(PackageVersions, caption = "Package Versions DadaWrapper")
knitr::kable(Input_DadaWrapper, caption = "Input arguments DadaWrapper")
knitr::kable(Input_DadaAssignTaxonomy, caption = "Input arguments Dada_WrapperAssignTaxonomyAddSpecies")
knitr::kable(tree_list[["PackageVersions"]], caption = "Package Versions for contruct_phylogenetic_tree")
knitr::kable(Input_constructTree, caption = "Input arguments for function construct_phylogenetic_tree")
knitr::kable(PackageVersionsAnal, caption = "Package Versions for this phyloseq analysis")
knitr::kable(Inputs_phyloseqAnalysis, caption = "Input arguments for this phyloseq analysis")
# phyloseq analysis starts here: so clear workspace:
# remove everything but input arguments, the phyloseq object, cbPalette, and loaded functions
rm(list = setdiff(ls(), c("cbPalette", "ps", as.character(Inputs_phyloseqAnalysis$Argument), lsf.str())))
df_ab_prev <- data.frame(ASV_ID = 1:ntaxa(ps),
total_counts_of_ASV = taxa_sums(ps),
prevalence = colSums(as(otu_table(ps), "matrix") != 0),
sparsity = colSums(as(otu_table(ps), "matrix") == 0),
mean_count_nonzero = apply(as(otu_table(ps), "matrix"), 2, function(x){mean(x[x > 0])}),
median_count_nonzero = apply(as(otu_table(ps), "matrix"), 2, function(x){median(x[x > 0])}))
df_ab_prev <- cbind(df_ab_prev, tax_table(ps))
TrrList <- plot_correlations_abundance_prev_sparsity(df_ab_prev, col = "Phylum")
TrList <- plotSVdistributions(seqtab = as(otu_table(ps), "matrix"), prevalence = prevalence)
Phyla <- dplyr::summarise(group_by(df_ab_prev, Phylum), ASVs = n(), PC_ASV = round(100*ASVs/ntaxa(ps),1), PC_total_prev = round(100*sum(prevalence)/sum(df_ab_prev$prevalence), 1),
PC_total_counts = round(100*sum(total_counts_of_ASV)/sum(df_ab_prev$total_counts_of_ASV), 1),
mean_prev_in_PC = round(100*mean(prevalence)/nsamples(ps), 1),
mean_total_counts = round(mean(total_counts_of_ASV)),
median_total_counts = round(median(total_counts_of_ASV)))
knitr::kable(Phyla)
# print(xtable(Phyla, align = "|c|c|c|c|", digits = 1), include.rownames = FALSE)
ps <- subset_taxa(ps, !is.na(Phylum))
assignment_distribution <- get_assignemnt_distribution(tax_table(ps))
knitr::kable(assignment_distribution)
# look at the species that have been assigned ambiguously
the_ambiguous_species <- unname(tax_table(ps)[grep(pattern = "/", tax_table(ps)[,'Species']), c('Genus', 'Species')])
colnames(the_ambiguous_species) <- c("Genus", "Species")
knitr::kable(as.data.frame(the_ambiguous_species))
ps
extra_level = "Phylum"
ps_extra <- tax_glom(ps, taxrank = extra_level, NArm = FALSE)
library_size_adjust_list <- adj_LS(ps_extra)
ps_tca_extra <- library_size_adjust_list[[1]]
SFs <- library_size_adjust_list[[2]] # NB: differs from SFs from ASVs but correlated
filterList <- plot_abundance_prev_filter(physeq = ps_tca_extra, prevalence = prevalence, taxa_sums_quantile = taxa_sums_quantile)
ps_tca_filt_extra <- filter_taxa(ps_tca_extra, function(x){(sum(x > min_obs) > (prevalence/100)*length(x)) || (sum(x) > quantile(taxa_sums(ps_tca_extra), probs = taxa_sums_quantile/100))}, prune = TRUE)
ps_filt_extra <- prune_taxa(taxa_names(ps_tca_filt_extra), ps_extra) # needed for DESeq2Apply_physeq
ps_filt_ra_extra <- transform_sample_counts(ps_filt_extra, function(x){x/sum(x)}) # same for ps_tca_filt
Tr_bar <- plot_bar_own(physeq = ps_filt_ra_extra, x = "Sample", group_var = group_var, fill = extra_level)
plot_list[[5]] <- Tr_bar
Tr_bar
group_var
extra_level
rm(list = ls())
setwd("~/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel")
# source("https://bioconductor.org/biocLite.R")
# biocLite("phyloseq")
library(phyloseq); packageVersion("phyloseq")
library(dada2); packageVersion("dada2")
library(vegan); packageVersion("vegan")
library(ggplot2); packageVersion("ggplot2")
library(dplyr); packageVersion("dplyr")
library(tidyr); packageVersion("tidyr")
library(gridExtra); packageVersion("gridExtra")
library(xtable); packageVersion("xtable")
library(RVAideMemoire); packageVersion("RVAideMemoire")
library(viridis); packageVersion("viridis")
library(scales); packageVersion("scales") # for the oob = squish option in gradient plots
library(ggthemes); packageVersion("ggthemes")
library(DESeq2); packageVersion("DESeq2")
PackageVersions <- data.frame(R = version$version.string,
dada2 = packageVersion("dada2"),
vegan = packageVersion("vegan"),
ggplot2 = packageVersion("ggplot2"),
dplyr = packageVersion("dplyr"),
tidyr = packageVersion("tidyr"),
gridExtra = packageVersion("gridExtra"),
xtable = packageVersion("xtable"),
viridis = packageVersion("viridis"),
scales = packageVersion("scales"),
ggthemes = packageVersion("ggthemes"),
DESeq2 = packageVersion("DESeq2"))
for (i in 1:ncol(PackageVersions)){PackageVersions[,i] <- as.character(PackageVersions[,i])}
PackageVersionsAnal <- tidyr::gather(PackageVersions, key = Package, value = Version)
extra_level = "Family"
prevalence <- 20 # in percent
min_obs <- 0L # a taxon will be considered present (for prevalence) if count > min_obs
taxa_sums_quantile <- 90 # in percent, taxa whose taxa_sums are above this threshold will be kept even if they do not pass prevalence
seed <- 1234
step_size <- 200 # for rarefaction curves
rare_level <- NULL # if NULL, min(sample_sums(ps)) is used!
rare_type <- "vegan" # either "sample" or "vegan"
rare_max_total <- NULL # maximal total amplicons value to which rarefaction curves are calculated, if NULL: quantile(sample_sums(ps), probs = .25) is used
taxa_are_rows = FALSE
group_var <- "Group" # tha variable based on which samples will be grouped
group_var_levels <- c("Young", "MiddleAged", "Old") # the factor levels of the group_var in the order you want them in your plots (set to NULL if you do not care)
second_ccp_variable <- "Sample.Integrity"
shape <- NULL # used for some plots to distinguish samples within the different levels of group_var
alpha_div_measures <- c("Observed", "Shannon") # not to change currently
alpha_at_genus <- FALSE
dist_methods <- c("jsd", "bray", "unifrac") # otions: see unlist(distanceMethodList)
datapath <- "/Users/jvb740/MarieCurie_Work/MouseProject/ResultsAndProtocols/ManiAging_Results/16S_Sequencing/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
taxonomy.path <- "Dada_Taxonomy/Silva_v128/Taxonomy_Silva128_minBoot50_allowMT.RData"
tree.path <- "Dada_phylogenetic_tree/phylog_tree.rds"
sample.path <- "sample_data/samdf.rds"
functionpath <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions/"
load(file.path(datapath, "Dada_Data/DenoisedData.RData"))
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
load(file.path(datapath, taxonomy.path))
tree_list <- readRDS(file.path(datapath, tree.path))
samdf <- readRDS(file.path(datapath, sample.path))
if (!is.null(group_var) && !is.null(group_var_levels)){
samdf[[group_var]] <- factor(samdf[[group_var]], levels = group_var_levels, ordered = TRUE)
}
sample.names <- rownames(seqtab.nochim)
if (!all.equal(sample.names, names(F_QualityStats))) {
stop("check sample names")
}
if (!all.equal(sample.names, as.character(ReadSummary$Sample))) {
stop("check sample names")
}
source(file.path(functionpath, "Dada_TaxonomyFunctions.R"))
source(file.path(functionpath, "Dada_PlotFunctions.R"))
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows = taxa_are_rows),
sample_data(samdf),
tax_table(taxa.species),
phy_tree(tree_list[["fitGTR"]]$tree))
FilteredReads <- ReadSummary[,c("Sample","FilteredReads")]
FilteredReads <- FilteredReads[match(sample_names(ps), FilteredReads$Sample),]
sample_data(ps)$FilteredReads <- FilteredReads$FilteredReads
if (!identical(sample_names(ps), sample.names)) {
stop("check sample names")
}
ps
# -- DadaWrapper --
Input_DadaWrapper <- data.frame(Argument = names(Input),
Value = sapply(Input, function(x){
if (is.null(x)){
"NULL"
} else if (length(x) > 5) {
"long entry"
} else if (length(x) > 1 && length(x) < 6){
paste(x, collapse = "; ")
} else {
as.character(x)
}}))
rownames(Input_DadaWrapper) <- NULL
# ----
# -- Dada_WrapperAssignTaxonomyAddSpecies --
InputSave <- InputSave[c("minBoot", "allowMultiple", "tryRC", "PathToRefs", "RefDataBase", "SpeciesDB", "PathToSave")]
Input_DadaAssignTaxonomy <- data.frame(Argument = names(unlist(InputSave)), Value = unlist(InputSave))
rownames(Input_DadaAssignTaxonomy) <- NULL
# ----
# -- construct_phylogenetic_tree -
Input_constructTree <- data.frame(Argument = names(tree_list[["Inputs"]]),
Value = sapply(tree_list[["Inputs"]], function(x){
if (length(x) > 1) {
"long entry"
} else {
as.character(x)
}}))
rownames(Input_constructTree) <- NULL
# ----
# -- This phyloseq analysis --
if (is.null(rare_level)) {
rare_level <- min(sample_sums(ps))
}
if (is.null(rare_max_total)){
rare_max_total <- quantile(sample_sums(ps), probs = .25)
}
Inputs_phyloseqAnalysis <- list(extra_level = extra_level,
prevalence = prevalence,
min_obs = min_obs,
taxa_sums_quantile = taxa_sums_quantile,
seed = seed,
step_size = step_size,
rare_level = rare_level,
rare_type = rare_type,
rare_max_total = rare_max_total,
taxa_are_rows = taxa_are_rows,
group_var = group_var,
group_var_levels = group_var_levels,
second_ccp_variable = second_ccp_variable,
shape = shape,
alpha_div_measures = alpha_div_measures,
alpha_at_genus = alpha_at_genus,
dist_methods = dist_methods,
datapath = datapath,
taxonomy.path = taxonomy.path,
tree.path = tree.path,
sample.path = sample.path,
functionpath = functionpath)
Inputs_phyloseqAnalysis <- data.frame(Argument = names(Inputs_phyloseqAnalysis),
Value = sapply(Inputs_phyloseqAnalysis, function(x){
if (is.null(x)){
"NULL"
} else if (length(x) > 7) {
"long entry"
} else if (length(x) > 1 && length(x) < 8){
paste(x, collapse = "; ")
} else {
as.character(x)
}}))
rownames(Inputs_phyloseqAnalysis) <- NULL
# ----
knitr::kable(PackageVersions, caption = "Package Versions DadaWrapper")
knitr::kable(Input_DadaWrapper, caption = "Input arguments DadaWrapper")
knitr::kable(Input_DadaAssignTaxonomy, caption = "Input arguments Dada_WrapperAssignTaxonomyAddSpecies")
knitr::kable(tree_list[["PackageVersions"]], caption = "Package Versions for contruct_phylogenetic_tree")
knitr::kable(Input_constructTree, caption = "Input arguments for function construct_phylogenetic_tree")
knitr::kable(PackageVersionsAnal, caption = "Package Versions for this phyloseq analysis")
knitr::kable(Inputs_phyloseqAnalysis, caption = "Input arguments for this phyloseq analysis")
# -- DadaWrapper --
Input_DadaWrapper <- data.frame(Argument = names(Input),
Value = sapply(Input, function(x){
if (is.null(x)){
"NULL"
} else if (length(x) > 5) {
"long entry"
} else if (length(x) > 1 && length(x) < 6){
paste(x, collapse = "; ")
} else {
as.character(x)
}}))
rownames(Input_DadaWrapper) <- NULL
# ----
# -- Dada_WrapperAssignTaxonomyAddSpecies --
InputSave <- InputSave[c("minBoot", "allowMultiple", "tryRC", "PathToRefs", "RefDataBase", "SpeciesDB", "PathToSave")]
Input_DadaAssignTaxonomy <- data.frame(Argument = names(unlist(InputSave)), Value = unlist(InputSave))
rownames(Input_DadaAssignTaxonomy) <- NULL
# ----
# -- construct_phylogenetic_tree -
Input_constructTree <- data.frame(Argument = names(tree_list[["Inputs"]]),
Value = sapply(tree_list[["Inputs"]], function(x){
if (length(x) > 1) {
"long entry"
} else {
as.character(x)
}}))
rownames(Input_constructTree) <- NULL
# ----
# -- This phyloseq analysis --
if (is.null(rare_level)) {
rare_level <- min(sample_sums(ps))
}
if (is.null(rare_max_total)){
rare_max_total <- quantile(sample_sums(ps), probs = .25)
}
Inputs_phyloseqAnalysis <- list(extra_level = extra_level,
prevalence = prevalence,
min_obs = min_obs,
taxa_sums_quantile = taxa_sums_quantile,
seed = seed,
step_size = step_size,
rare_level = rare_level,
rare_type = rare_type,
rare_max_total = rare_max_total,
taxa_are_rows = taxa_are_rows,
group_var = group_var,
group_var_levels = group_var_levels,
second_ccp_variable = second_ccp_variable,
shape = shape,
alpha_div_measures = alpha_div_measures,
alpha_at_genus = alpha_at_genus,
dist_methods = dist_methods,
datapath = datapath,
taxonomy.path = taxonomy.path,
tree.path = tree.path,
sample.path = sample.path,
functionpath = functionpath)
Inputs_phyloseqAnalysis <- data.frame(Argument = names(Inputs_phyloseqAnalysis),
Value = sapply(Inputs_phyloseqAnalysis, function(x){
if (is.null(x)){
"NULL"
} else if (length(x) > 7) {
"long entry"
} else if (length(x) > 1 && length(x) < 8){
paste(x, collapse = "; ")
} else {
as.character(x)
}}))
rownames(Inputs_phyloseqAnalysis) <- NULL
# ----
knitr::kable(PackageVersions, caption = "Package Versions DadaWrapper")
knitr::kable(Input_DadaWrapper, caption = "Input arguments DadaWrapper")
knitr::kable(Input_DadaAssignTaxonomy, caption = "Input arguments Dada_WrapperAssignTaxonomyAddSpecies")
knitr::kable(tree_list[["PackageVersions"]], caption = "Package Versions for contruct_phylogenetic_tree")
knitr::kable(Input_constructTree, caption = "Input arguments for function construct_phylogenetic_tree")
knitr::kable(PackageVersionsAnal, caption = "Package Versions for this phyloseq analysis")
knitr::kable(Inputs_phyloseqAnalysis, caption = "Input arguments for this phyloseq analysis")
ps
# phyloseq analysis starts here: so clear workspace:
# remove everything but input arguments, the phyloseq object, cbPalette, and loaded functions
rm(list = setdiff(ls(), c("cbPalette", "ps", as.character(Inputs_phyloseqAnalysis$Argument), lsf.str())))
df_ab_prev <- data.frame(ASV_ID = 1:ntaxa(ps),
total_counts_of_ASV = taxa_sums(ps),
prevalence = colSums(as(otu_table(ps), "matrix") != 0),
sparsity = colSums(as(otu_table(ps), "matrix") == 0),
mean_count_nonzero = apply(as(otu_table(ps), "matrix"), 2, function(x){mean(x[x > 0])}),
median_count_nonzero = apply(as(otu_table(ps), "matrix"), 2, function(x){median(x[x > 0])}))
df_ab_prev <- cbind(df_ab_prev, tax_table(ps))
TrrList <- plot_correlations_abundance_prev_sparsity(df_ab_prev, col = "Phylum")
TrList <- plotSVdistributions(seqtab = as(otu_table(ps), "matrix"), prevalence = prevalence)
Phyla <- dplyr::summarise(group_by(df_ab_prev, Phylum), ASVs = n(), PC_ASV = round(100*ASVs/ntaxa(ps),1), PC_total_prev = round(100*sum(prevalence)/sum(df_ab_prev$prevalence), 1),
PC_total_counts = round(100*sum(total_counts_of_ASV)/sum(df_ab_prev$total_counts_of_ASV), 1),
mean_prev_in_PC = round(100*mean(prevalence)/nsamples(ps), 1),
mean_total_counts = round(mean(total_counts_of_ASV)),
median_total_counts = round(median(total_counts_of_ASV)))
knitr::kable(Phyla)
# print(xtable(Phyla, align = "|c|c|c|c|", digits = 1), include.rownames = FALSE)
ps <- subset_taxa(ps, !is.na(Phylum))
v
extra_level = "Phylum"
ps_extra <- tax_glom(ps, taxrank = extra_level, NArm = FALSE)
library_size_adjust_list <- adj_LS(ps_extra)
ps_tca_extra <- library_size_adjust_list[[1]]
SFs <- library_size_adjust_list[[2]] # NB: differs from SFs from ASVs but correlated
filterList <- plot_abundance_prev_filter(physeq = ps_tca_extra, prevalence = prevalence, taxa_sums_quantile = taxa_sums_quantile)
ps_tca_filt_extra <- filter_taxa(ps_tca_extra, function(x){(sum(x > min_obs) > (prevalence/100)*length(x)) || (sum(x) > quantile(taxa_sums(ps_tca_extra), probs = taxa_sums_quantile/100))}, prune = TRUE)
ps_filt_extra <- prune_taxa(taxa_names(ps_tca_filt_extra), ps_extra) # needed for DESeq2Apply_physeq
ps_filt_ra_extra <- transform_sample_counts(ps_filt_extra, function(x){x/sum(x)}) # same for ps_tca_filt
Tr_bar <- plot_bar_own(physeq = ps_filt_ra_extra, x = "Sample", group_var = group_var, fill = extra_level)
Tr_bar
physeq = ps_filt_ra_extra
ps_filt_ra_extra
x = "Sample"
fill = extra_level
if(taxa_are_rows(physeq)) { physeq <- t(physeq) }
if (!is.factor(sample_data(physeq)[[group_var]])) {sample_data(physeq)[[group_var]] <- as.factor(sample_data(physeq)[[group_var]])}
if (is.null(fill)) { fill = "Phylum"}
mdf <- psmelt(physeq)
View(mdf)
source(file.path(functionpath, "Dada_PlotFunctions.R"))
Tr_bar <- plot_bar_own(physeq = ps_filt_ra_extra, x = "Sample", group_var = group_var, fill = extra_level)
Tr_bar
getwd()
physeq
ps_filt_extra
saveRDS(object = ps_filt_extra, "ps_filt_extra.rds")
group_var
functionpath
source(file.path(functionpath, "Dada_TaxonomyFunctions.R"))
rm(list = ls())
readRDS(file = "ps_filt_extra.rds")
group_var = "Group"
functionpath <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions/"
source(file.path(functionpath, "Dada_TaxonomyFunctions.R"))
raw_TbTmatrixes_list <- calculate_raw_TbTmatrixes(ps_filt_extra, group_var = group_var)
rm(list = ls())
ps_filt_extra <- readRDS(file = "ps_filt_extra.rds")
group_var = "Group"
functionpath <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions/"
source(file.path(functionpath, "Dada_TaxonomyFunctions.R"))
raw_TbTmatrixes_list <- calculate_raw_TbTmatrixes(ps_filt_extra, group_var = group_var)
names(raw_TbTmatrixes_list)
TbTmatrixes <- raw_TbTmatrixes_list[[2]]
names(TbTmatrixes)
Mat <- TbTmatrixes[[1]]
View(Mat)
View(Mat)
colnames(Mat)
group_fac <- sample_data(ps_filt_extra)[[group_var]]
group_fac
as.numeric(group_fac) %in% c(1, 3)
group_fac <- sample_data(ps_filt_extra)[[group_var]]
group_fac <- droplevels(group_fac[as.numeric(group_fac) %in% c(1, 3)])
group_fac
i = 1
mat <- TbTmatrixes[[i]]
rm(Mat)
View(mat)
mat_rank <- t(apply(mat, 1, rank, na.last = "keep"))
View(mat_rank)
mat_rank <- t(apply(mat, 1, rank, na.last = "keep"))
rowSums(mat_rank)
nrow(mat)
ncol(mat)
ncol(mat)*(ncol(mat) + 1)/2
gm_own
rower <- mat_rank[1,]
rower
gm_own
gm_own(rower)
log(1)
rank(c(1,1, NA, 2), na.last = "keep")
sum(rank(c(1,1, NA, 2), na.last = "keep"))
sum(rank(c(1,1, NA, 2), na.last = "keep"), na.rm = T)
sum(rank(c(1,1, 1, 2), na.last = "keep"))
rank(c(1,1, 1, 2), na.last = "keep")
gm_own(x = c(1,1,1,2))
gm_own(x = c(1,1,NA,2))
gm_own
3/6
log(3)/log(6)
log(0)
log(NA)
GMs <- apply(mat_rank, 1, gm_own, na.rm = TRUE)
GMs
gm(own)
gm_own
SumOfLogs <- rowSums(log(mat_rank), na.rm = TRUE)
SumOfLogs
log(mat_rank)
gm(own)
gm_own
?length
gm_own(c(1, 2, 3, NA))
gm_own(c(1, 2, 3, NA), na.rm = TRUE)
gm_own(c(1, 2, 3), na.rm = TRUE)
x <- c(1,2,3,NA)
x > 0
x[x>0]
runApp('~/Coursera_MOOC/20161202_LearningShiny_FantasySports/shinyy/Apps/Shinyappsio/170328_Vocabulary/app_Voc.R')
rm(list = ls())
setwd("~/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel")
ps_filt_extra <- readRDS(file = "ps_filt_extra.rds")
group_var = "Group"
functionpath <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions/"
source(file.path(functionpath, "Dada_TaxonomyFunctions.R"))
raw_TbTmatrixes_list <- calculate_raw_TbTmatrixes(ps_filt_extra, group_var = group_var)
TbTmatrixes <- raw_TbTmatrixes_list[[2]]
group_fac <- sample_data(ps_filt_extra)[[group_var]]
group_fac <- droplevels(group_fac[as.numeric(group_fac) %in% c(1, 3)])
group_fac
i = 1
mat <- TbTmatrixes[[i]]
View(mat)
mat_rank <- t(apply(mat, 1, rank, na.last = "keep"))
View(mat_rank)
ncol(mat)*(ncol(mat) + 1)/2
rowSums(mat_rank)
gm_own
x <- c(1,2,NA)
x > 1
length(x)
sum(x, na.rm = T)
length(x[!is.na(x)])
log(NaN)
rank(c(1,2,NaN))
gm_own_tbt = function(x){
exp(sum(log(x), na.rm = TRUE) / length(x[!is.na(x)]))
}
x
gm_own(x, na.rm = T, zeros.count = FALSE)
gm_own_tbt(x)
x
log(x)
GMs <- apply(mat_rank, 1, gm_own_tbt)
GMs
rank(c(1,2,NaN))
rank(c(1,2,NaN), na.last = "keep")
gm_own_tbt(x)
sqrt(2)
c(1,2) * sqrt(2)
c(1,2) / sqrt(2)
(c(1,2) / sqrt(2))[1]
(c(1,2) / sqrt(2))[1] * (c(1,2) / sqrt(2))[2]
prod(c(1,2) / sqrt(2))
log(NA)
mat_rank <- t(apply(mat, 1, rank, na.last = "keep"))
View(mat_rank)
apply(mat_rank, 1, function(taxa_ranks){
log(taxa_ranks) - log(gm_own_tbt(taxa_ranks))
})
mat_rank_divgm_log <- apply(mat_rank, 1, function(taxa_ranks){
log(taxa_ranks) - log(gm_own_tbt(taxa_ranks))
})
View(mat_rank_divgm_log)
mat_rank_divgm_log <- t(apply(mat_rank, 1, function(taxa_ranks){
log(taxa_ranks) - log(gm_own_tbt(taxa_ranks))
}))
View(mat_rank_divgm_log)
log(NA)
log(NA) - 15
rowSums(mat_rank_divgm_log)
max(rowSums(mat_rank_divgm_log))
max(rowSums(mat_rank_divgm_log)) == 0
all.equal(max(rowSums(mat_rank_divgm_log)), 0)
?quantile
