Median_QS = Score[which(cumsum(Count)/sum(Count) >= .5)][[1]],
q25_QS = Score[which(cumsum(Count)/sum(Count) >= .25)][[1]],
q75_QS = Score[which(cumsum(Count)/sum(Count) >= .75)][[1]])
## Check that all reads are of same length
x <- range(Current_dfQStatsRV$NoReads)
if (!all.equal(x[1], x[2], tolerance = .Machine$double.eps ^ 0.5)) {
stop("Not all reads of same length in file", R_fastq[i])
}
R_QualityStats[[i]] <- as.data.frame(Current_dfQStatsRV)
rm(Current_FWfq, Current_dfFW, Current_dfQStatsFW,
Current_RVfq, Current_dfRV, Current_dfQStatsRV, x)
}
QS_Median_OverviewPlot(F_QualityStats, SampleNames)
SampleNames
# add the sample names as names to the lists:
names(F_QualityStats) <- SampleNames
names(R_QualityStats) <- SampleNames
QS_Median_OverviewPlot(F_QualityStats, SampleNames)
FilteredFolder <- file.path(path2, "Dada_FilteredFastqs")
FilteredFolder
filtFs <- file.path(FilteredFolder, paste0(SampleNames, "_F_Filtered.fastq.gz"))
filtRs <- file.path(FilteredFolder, paste0(SampleNames, "_R_Filtered.fastq.gz"))
names(filtFs) <- SampleNames
names(filtRs) <- SampleNames
filtFs
?fastqPairedFilter
i
i = 1
fout = c(filtFs[i], filtRs[i])
fout
fls = filtFs
fls
nreads = nreadsLearn
NREADS <- 0
drps <- vector("list", length(fls))
i = 1
dada2:::is.list.of(fls, "derep")
drps[[i]] <- derepFastq(fls[[i]])
fls[[1]]
path2
exists("/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20180724_Reads/Dada_Analysis_pooled//Dada_FilteredFastqs/SN-1_F_Filtered.fastq.gz")
fls[[1]] <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20180724_Reads/Dada_Analysis_pooled/Dada_FilteredFastqs/SN-1_F_Filtered.fastq.gz"
fls[[1]]
drps[[i]] <- derepFastq(fls[[i]])
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
# CHANGE pathToFunctions here:
pathToFunctions <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions"
source(file.path(pathToFunctions, "Dada_PlotFunctions.R"))
source(file.path(pathToFunctions, "Dada_WrapFunctions.R"))
rm(list = ls())
# CHANGE pathToFunctions here:
pathToFunctions <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions"
source(file.path(pathToFunctions, "Dada_PlotFunctions.R"))
source(file.path(pathToFunctions, "Dada_WrapFunctions.R"))
path = "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Clean"
F_pattern = "1.fq.gz"
R_pattern = "2.fq.gz"
path2 = "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_Pooled/"
nreadsLearn = 1.2e+06
## dada2:
# source("https://bioconductor.org/biocLite.R")
try(library(dada2), biocLite("dada2"))
## Short Read
try(library(ShortRead), biocLite("ShortRead"))
## ggplot2
try(library(ggplot2), install.packages("ggplot2"))
## dplyr
try(library(dplyr), install.packages("dplyr"))
## dplyr
try(library(tidyr), install.packages("tidyr"))
path2
folders <- list.dirs(path, recursive = FALSE, full.names = FALSE)
if(length(folders) != 0) {
SampleNames <- folders
if(sum(grepl("^Dada", SampleNames)) != 0){
warning("**There are folders starting with \"Dada\" in your path folder, maybe you have run the function on this path folder before\n.
The folders starting with Dada will not be considered sample folders!!\n Files within Dada_Data Dada_FilteredFastqs and Dada_Plots will be overwritten**")
}
# exclude Folders starting with "Dada" from the folders considered as sample fodlers
if(length(grep("^Dada", SampleNames))!=0) {
SampleNames <- SampleNames[-grep("^Dada", SampleNames)]
}
F_fastq <- character(length = length(SampleNames))
R_fastq <- character(length = length(SampleNames))
for (i in 1:length(SampleNames)) {
CurrentPath <- file.path(path, SampleNames[i])
if(sum(grepl(F_pattern, list.files(CurrentPath))) == 0) {
stop(paste("F_pattern fits no file in ", CurrentPath))
}
if(sum(grepl(F_pattern, list.files(CurrentPath))) > 1) {
stop(paste("F_pattern fits several files in ", CurrentPath))
}
if(sum(grepl(R_pattern, list.files(CurrentPath))) == 0) {
stop(paste("R_pattern fits no file in ", CurrentPath))
}
if(sum(grepl(R_pattern, list.files(CurrentPath))) > 1) {
stop(paste("R_pattern fits several files in ", CurrentPath))
}
F_fastq[i] <- file.path(CurrentPath, list.files(CurrentPath)[grepl(F_pattern, list.files(CurrentPath))])
R_fastq[i] <- file.path(CurrentPath, list.files(CurrentPath)[grepl(R_pattern, list.files(CurrentPath))])
}
} else {
stop("No sample folders were found in the given path! Currently the Dada2_wrap function can only handle the situation where the fastq files are in separate folders for each sample.
These folders have to be in the \"path\" folder. Other situations have to be added.")
}
F_fastq
DataFolder <- file.path(path2, "Dada_Data")
FilteredFolder <- file.path(path2, "Dada_FilteredFastqs")
FilteredFolder
FilteredFolder <- file.path(path, "Dada_FilteredFastqs")
filtFs <- file.path(FilteredFolder, paste0(SampleNames, "_F_Filtered.fastq.gz"))
filtRs <- file.path(FilteredFolder, paste0(SampleNames, "_R_Filtered.fastq.gz"))
names(filtFs) <- SampleNames
names(filtRs) <- SampleNames
filtFs
fls = filtFs
nreads = nreadsLearn
NREADS <- 0
drps <- vector("list", length(fls))
dada2:::is.list.of(fls, "derep")
drps[[i]] <- derepFastq(fls[[i]])
SampleNames
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
filtFs
nreadsLearn = 1.2e+06
path = "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Clean"
F_pattern = "1.fq.gz"
R_pattern = "2.fq.gz"
path2 = "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_Pooled/"
folders <- list.dirs(path, recursive = FALSE, full.names = FALSE)
if(length(folders) != 0) {
SampleNames <- folders
if(sum(grepl("^Dada", SampleNames)) != 0){
warning("**There are folders starting with \"Dada\" in your path folder, maybe you have run the function on this path folder before\n.
The folders starting with Dada will not be considered sample folders!!\n Files within Dada_Data Dada_FilteredFastqs and Dada_Plots will be overwritten**")
}
# exclude Folders starting with "Dada" from the folders considered as sample fodlers
if(length(grep("^Dada", SampleNames))!=0) {
SampleNames <- SampleNames[-grep("^Dada", SampleNames)]
}
F_fastq <- character(length = length(SampleNames))
R_fastq <- character(length = length(SampleNames))
for (i in 1:length(SampleNames)) {
CurrentPath <- file.path(path, SampleNames[i])
if(sum(grepl(F_pattern, list.files(CurrentPath))) == 0) {
stop(paste("F_pattern fits no file in ", CurrentPath))
}
if(sum(grepl(F_pattern, list.files(CurrentPath))) > 1) {
stop(paste("F_pattern fits several files in ", CurrentPath))
}
if(sum(grepl(R_pattern, list.files(CurrentPath))) == 0) {
stop(paste("R_pattern fits no file in ", CurrentPath))
}
if(sum(grepl(R_pattern, list.files(CurrentPath))) > 1) {
stop(paste("R_pattern fits several files in ", CurrentPath))
}
F_fastq[i] <- file.path(CurrentPath, list.files(CurrentPath)[grepl(F_pattern, list.files(CurrentPath))])
R_fastq[i] <- file.path(CurrentPath, list.files(CurrentPath)[grepl(R_pattern, list.files(CurrentPath))])
}
} else {
stop("No sample folders were found in the given path! Currently the Dada2_wrap function can only handle the situation where the fastq files are in separate folders for each sample.
These folders have to be in the \"path\" folder. Other situations have to be added.")
}
fls = filtFs
nreads = nreadsLearn
fls
fls[1]
i = 1
Current_FWfq <- fls[i]
Current_dfFW <- qa(Current_FWfq, n = 1e06)[["perCycle"]]$quality
View(Current_dfFW)
Current_dfFW <- dplyr::group_by(Current_dfFW, Cycle)
Current_dfQStatsFW <- dplyr::summarise(
Current_dfFW,
NoReads = sum(Count),
Mean_QS = sum(Count*Score)/sum(Count),
SD_QS = sqrt(sum(Count*((Score-Mean_QS)^2))/(NoReads-1)),
Median_QS = Score[which(cumsum(Count)/sum(Count) >= .5)][[1]],
q25_QS = Score[which(cumsum(Count)/sum(Count) >= .25)][[1]],
q75_QS = Score[which(cumsum(Count)/sum(Count) >= .75)][[1]])
View(Current_dfQStatsFW)
fls
nreads
drps[[1]]
i
drps[[i]] <- derepFastq(fls[[i]])
drps <- vector("list", length(fls))
drps[[i]] <- derepFastq(fls[[i]])
drp <- drps[[1]]
drp
drps$quals
drp$quals
names(drp)
length(drp$uniques)
fls
?dada
body(dada2::learnErrors)
?learnErrors
drps
i = 2
drps[[i]] <- derepFastq(fls[[i]])
drps <- drps[1:i]
dds <- dada(drps, err = NULL, selfConsist = TRUE, multithread = multithread)
multithresd = TRUE
multithread = TRUE
dds <- dada(drps, err = NULL, selfConsist = TRUE, multithread = multithread)
dds
sample_order <- 1:length(fls)
sample_order
sample(sample_order)
sample(sample_order)
sample(sample_order)
drps <- vector("list", length(fls))
drps
drps[[2]] <- "c"
sample_order
sample_order <- sample(sample_order)
sample_order
drps
drps[[4]] <- "c"
drps <- vector("list", length(fls))
drps[sample_order[1:3]]
drps[sample_order[1:3]] <- "C"
drps
drps <- drps[sample_order[1:i]]
drps
i
sample_order
drps <- vector("list", length(fls))
drps[sample_order[1:i]] <- "C"
drps
i
drps[[6]] <- 6
drps
drps <- drps[sample_order[1:i]]
dprs
drps <- drps[sample_order[1:i]]
drps
drps <- vector("list", length(fls))
sample_order <- 1:length(fls)
sample_order <- sample(sample_order)
sample_order
i = 4
drps
drps[sample_order[1:i]]
drps[sample_order[1:i]] <- "C"
drps
drps[sample_order[1:i]]
drps
drps[[6]] <- "c"
sample_order
drps <- drps[sample_order[1:i]]
drps
sort(sample_order[1:i])
drps <- vector("list", length(fls))
drps[sample_order[1:i]] <- "C"
drps
drps[[6]] <- "c"
sample_order[1:i]
drps <- drps[sort(sample_order[1:i])]
drps
filtFs
i = 1
Current_FWfq <- filtFs[i]
Current_dfFW <- qa(Current_FWfq, n = 1e06)[["perCycle"]]$quality
# df is a data frame containing for each cycle (nt) the distribution of Quality scores
# e.g. Cycle 1 had 7 different quality scores, then 7 rows of cycle one, for each score the count says how many reads had this score
Current_dfFW <- dplyr::group_by(Current_dfFW, Cycle)
Current_dfQStatsFW <- dplyr::summarise(
Current_dfFW,
NoReads = sum(Count),
Mean_QS = sum(Count*Score)/sum(Count),
SD_QS = sqrt(sum(Count*((Score-Mean_QS)^2))/(NoReads-1)),
Median_QS = Score[which(cumsum(Count)/sum(Count) >= .5)][[1]],
q25_QS = Score[which(cumsum(Count)/sum(Count) >= .25)][[1]],
q75_QS = Score[which(cumsum(Count)/sum(Count) >= .75)][[1]])
# Check that all reads are of same length
x <- range(Current_dfQStatsFW$NoReads)
if (!all.equal(x[1], x[2], tolerance = .Machine$double.eps ^ 0.5)) {
stop("Not all reads of same length in file", F_fastq[i])
}
F_QualityStats_filtered[[i]] <- as.data.frame(Current_dfQStatsFW)
# collect the same stats for the RV FastQ files
Current_RVfq <- filtFs[i]
Current_dfRV <- qa(Current_RVfq, n = 1e06)[["perCycle"]]$quality
F_QualityStats_filtered <- list()
R_QualityStats_filtered <- list()
Current_dfRV <- dplyr::group_by(Current_dfRV, Cycle)
Current_dfQStatsRV <- dplyr::summarise(
Current_dfRV,
NoReads = sum(Count),
Mean_QS = sum(Count*Score)/sum(Count),
SD_QS = sqrt(sum(Count*((Score-Mean_QS)^2))/(NoReads-1)),
Median_QS = Score[which(cumsum(Count)/sum(Count) >= .5)][[1]],
q25_QS = Score[which(cumsum(Count)/sum(Count) >= .25)][[1]],
q75_QS = Score[which(cumsum(Count)/sum(Count) >= .75)][[1]])
## Check that all reads are of same length
x <- range(Current_dfQStatsRV$NoReads)
if (!all.equal(x[1], x[2], tolerance = .Machine$double.eps ^ 0.5)) {
stop("Not all reads of same length in file", R_fastq[i])
}
filtFs
# add the sample names as names to the lists:
names(F_QualityStats_filtered) <- SampleNames
filtFs
sam <- SampleNames
sam <- SampleNames[1]
sam
derepF <- derepFastq(filtFs[[sam]])
names(derepF)
derepF$uniques
range(derepF$uniques)
err_F
ddF <- dada(derepF, err=err_F, multithread=TRUE)
sum(derepF$uniques)
length(derepF$uniques)
plot(derepF$uniques)
names(ddF)
length(ddF$denoised)
length(derepF$uniques)
length(ddF$denoised)
?mergePairs
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
load(file.path(datapath, "Dada_Data/DenoisedData"))
load(file.path(datapath, "Dada_Data/DenoisedData.RData"))
names(mergers)
# get mergers from going throught the DanFunD data
Df <- mergers[[1]]
View(Df)
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
path = "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Clean"
F_pattern = "1.fq.gz"
R_pattern = "2.fq.gz"
path2 = "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis_Pooled/"
folders <- list.dirs(path, recursive = FALSE, full.names = FALSE)
if(length(folders) != 0) {
SampleNames <- folders
if(sum(grepl("^Dada", SampleNames)) != 0){
warning("**There are folders starting with \"Dada\" in your path folder, maybe you have run the function on this path folder before\n.
The folders starting with Dada will not be considered sample folders!!\n Files within Dada_Data Dada_FilteredFastqs and Dada_Plots will be overwritten**")
}
# exclude Folders starting with "Dada" from the folders considered as sample fodlers
if(length(grep("^Dada", SampleNames))!=0) {
SampleNames <- SampleNames[-grep("^Dada", SampleNames)]
}
F_fastq <- character(length = length(SampleNames))
R_fastq <- character(length = length(SampleNames))
for (i in 1:length(SampleNames)) {
CurrentPath <- file.path(path, SampleNames[i])
if(sum(grepl(F_pattern, list.files(CurrentPath))) == 0) {
stop(paste("F_pattern fits no file in ", CurrentPath))
}
if(sum(grepl(F_pattern, list.files(CurrentPath))) > 1) {
stop(paste("F_pattern fits several files in ", CurrentPath))
}
if(sum(grepl(R_pattern, list.files(CurrentPath))) == 0) {
stop(paste("R_pattern fits no file in ", CurrentPath))
}
if(sum(grepl(R_pattern, list.files(CurrentPath))) > 1) {
stop(paste("R_pattern fits several files in ", CurrentPath))
}
F_fastq[i] <- file.path(CurrentPath, list.files(CurrentPath)[grepl(F_pattern, list.files(CurrentPath))])
R_fastq[i] <- file.path(CurrentPath, list.files(CurrentPath)[grepl(R_pattern, list.files(CurrentPath))])
}
} else {
stop("No sample folders were found in the given path! Currently the Dada2_wrap function can only handle the situation where the fastq files are in separate folders for each sample.
These folders have to be in the \"path\" folder. Other situations have to be added.")
}
SampleNames
mergers <- vector("list", length(SampleNames))
names(mergers) <- SampleNames
NoFilteredReads <- vector("numeric", length(SampleNames))
names(NoFilteredReads) <- SampleNames
Uniques_F <- vector("numeric", length(SampleNames))
names(Uniques_F) <- SampleNames
Uniques_R <- vector("numeric", length(SampleNames))
names(Uniques_R) <- SampleNames
Denoised_F <- vector("numeric", length(SampleNames))
names(Denoised_F) <- SampleNames
Denoised_R <- vector("numeric", length(SampleNames))
names(Denoised_R) <- SampleNames
sam <- SampleNames[1]
derepF <- derepFastq(filtFs[[sam]])
names(derepF)
?derepFastq
quals <- derepF_quals
quals <- derepF$quals
dim(quals)
maps <- derepF$map
class(maps)
maps
range(maps)
length(maps)
sum(derepF$uniques)
length(derepF$map)
ddF <- dada(derepF, err=err_F, multithread=TRUE)
?dada
ddF$denoised
length(dd_F$denoised)
length(ddF$denoised)
sum(ddf$denoised)
sum(ddF$denoised)
length(derepF$map)
sum(derepF$uniques)
ddF <- dada(derepF, err=err_F, multithread=TRUE)
ddf$clustering -> Testi
ddF$clustering -> Testi
View(Testi)
sum(Testi$abundance)
ddF$map
length(derepF$uniques)
length(ddF$denoised)
derepR <- derepFastq(filtRs[[sam]])
ddR <- dada(derepR, err=err_R, multithread=TRUE)
?mergePairs
minOverlap = 30, maxMismatch = 0
minOverlap = 30
maxMismatch = 0
mergers <- mergePairs(dd_F, drp_F, dd_R, drp_R, minOverlap = minOverlap, maxMismatch = maxMismatch)
merger <- mergePairs(ddF, derepF, ddR, derepR, minOverlap = minOverlap, maxMismatch = maxMismatch)
View(merger)
table(merger$forward)
# get mergers from going throught the DanFunD data
Df <- mergers[[1]]
ddF <- dd_F[[1]]
drpF <- drp_F[[1]]
ddR <- dd_R[[1]]
drpR <- drp_R[[1]]
# Df tells you that denoised F 1 fitted to denoised R 1 with abundance 1640.
# To get to the abundance you simply go backwards
# First from denoised to uniques using ddF$map and ddR$map
UniquesFittingDenoisedF1 <- which(ddF$map == 1)
UniquesFittingDenoisedR1 <- which(ddR$map == 1)
?removeBimeraDenovo
# generate also a read summary data frame
ReadSummary <- data.frame(Sample = SampleNames, NoReads = sapply(F_QualityStats, function(df){df$NoReads[1]}))
View(ReadSummary)
NoFilteredReads
View(ReadSummary)
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
load(file.path(datapath, "Dada_Data/DenoisedData.RData"))
SampleNames
View(ReadSummary)
SampleNames <- ReadSummary$Sample
if (!all(SampleNames %in% ReadSummary$Sample)) {
stop("not all SampleNames were found in the given ReadSummary")
}
ReadSummary <- ReadSummary[ReadSummary$Sample %in% SampleNames,]
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ReadSummary <- subset(ReadSummary, select = c("Sample", "NoReads", "FilteredReads", "MergedReads", "MergedReadsWOBimera"))
ReadSummary <- dplyr::arrange(ReadSummary, desc(NoReads))
LevelsWant <- as.character(ReadSummary$Sample)
for (i in seq_along(LevelsWant)) {
ReadSummary$Sample <- relevel(ReadSummary$Sample, ref = LevelsWant[i])
}
colnames(ReadSummary)[2:5] <- c("all", "filtered", "merged", "nochim")
View(ReadSummary)
ReadSummary <- tidyr::gather(ReadSummary, key = Type, value = NoReads, -Sample)
pal(cbPalette)
pal <- function(col, border = "light gray", ...){
n <- length(col)
plot(0, 0, type="n", xlim = c(0, 1), ylim = c(0, 1),
axes = FALSE, xlab = "", ylab = "", ...)
rect(0:(n-1)/n, 0, 1:n/n, 1, col = col, border = border)
}
pal(cbPalette)
color_levels <- cbPalette[2:7]
color_levels
names(color_levels) <- c("all", "filtered", "denoised_FW", "denoised_RV", "merged", "nochim")
rm(list = ls())
# # ---- Sourcing the plot and wrapper functions ----
# # datapath <- "/emc/cbmr/data/MICROBIOME/raw/mouse/stool/2017-07-13_DK_age_ManiAging/Dada2_Analysis"
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/DK_Healthy_Normalization_20181023_Reads/Dada_Analysis"
load(file.path(datapath, "Dada_Data/QualityStats.RData"))
load(file.path(datapath, "Dada_Data/DenoisedData.RData"))
View(ReadSummary)
colnames(ReadSummary)
ReadSummary <- subset(ReadSummary, select = c("Sample", "UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera"))
View(ReadSummary)
colnames(ReadSummary)
color_levels <- cbPalette[2:7]
names(color_levels) <- c("UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera")
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
color_levels <- cbPalette[2:7]
names(color_levels) <- c("UniqueSequences_F", "UniqueSequences_R", "DenoisedSequences_F", "DenoisedSequences_R", "Unique_Amplicons", "UniqueAmpliconsWOBimera")
color_levels
rm(list = ls())
